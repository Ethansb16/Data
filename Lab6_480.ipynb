{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ethansb16/Data/blob/main/Lab6_480.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make you own copy of this notebook. File>Save a Copy"
      ],
      "metadata": {
        "id": "ryuLbgY_Q83b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "77G4nTFrc4NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 6 – Day 1: Decision Trees on the Breast Cancer Dataset\n",
        "Dataset\n",
        "\n",
        "\n",
        "- We will use the Breast Cancer Wisconsin dataset, a built-in dataset from sklearn.datasets.\n",
        "\n",
        "- It contains 30 features computed from digitized images of a breast mass and a binary target: malignant or benign.\n",
        "\n",
        "\n",
        "Lab Tasks\n",
        "1. Setup"
      ],
      "metadata": {
        "id": "fsXUKwXTQzKg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KSV4C3tQucS"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load and Explore the Data"
      ],
      "metadata": {
        "id": "mlMLlJEcRd_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_breast_cancer()\n",
        "\n",
        "X, y = data.data, data.target\n",
        "\n",
        "print(\"Features:\", data.feature_names)\n",
        "\n",
        "print(\"Target names:\", data.target_names)\n",
        "\n",
        "print(\"Shape:\", X.shape)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vw6aQYSiReF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Split the Data"
      ],
      "metadata": {
        "id": "fPUAjL08RiBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "s8w2yeAORjRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Train the Decision Tree"
      ],
      "metadata": {
        "id": "BYEnUpcZRlUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-xVk9JIZRlct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Visualize the Tree"
      ],
      "metadata": {
        "id": "1Gnygi76RpbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plot_tree(clf, filled=True, feature_names=data.feature_names, class_names=data.target_names)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CWg7V1wQRrIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Evaluate the Classifier"
      ],
      "metadata": {
        "id": "3gRT6tfVRsvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Testing Accuracy:\", acc)\n",
        "\n",
        "y_pred2 = clf.predict(X_train)\n",
        "\n",
        "acc = accuracy_score(y_train, y_pred2)\n",
        "\n",
        "print(\"Training Accuracy:\", acc)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=data.target_names)\n",
        "\n",
        "disp.plot()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kYSCcabtRvcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer the accompanying reflection Questions"
      ],
      "metadata": {
        "id": "o3s7dF7R_Wet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 6 – Day 2: Feedforward Neural Networks on Fashion MNIST\n",
        "\n",
        "\n",
        "Objective\n",
        "- Train a dense (non-convolutional) neural network on image data using TensorFlow/Keras to classify clothing items.\n",
        "\n",
        "Setup\n",
        "- Requirements: Google Colab (no setup required, TensorFlow is pre-installed)\n",
        "\n",
        "Dataset: Fashion MNIST\n",
        "- A set of grayscale images (28×28) of clothing types.\n",
        "\n",
        "Classes:\n",
        "\n",
        "0: T-shirt/top\n",
        "\n",
        "\n",
        "1: Trouser\n",
        "\n",
        "\n",
        "2: Pullover\n",
        "\n",
        "\n",
        "3: Dress\n",
        "\n",
        "\n",
        "4: Coat\n",
        "\n",
        "\n",
        "5: Sandal\n",
        "\n",
        "\n",
        "6: Shirt\n",
        "\n",
        "\n",
        "7: Sneaker\n",
        "\n",
        "\n",
        "8: Bag\n",
        "\n",
        "\n",
        "9: Ankle boot\n",
        "\n",
        "\n",
        "1. Import Libraries\n"
      ],
      "metadata": {
        "id": "ekxtzQTnRu5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "baMU1pqZR--z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load and Normalize Data"
      ],
      "metadata": {
        "id": "xldTBCX9TxGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0  # Normalize to [0, 1]\n"
      ],
      "metadata": {
        "id": "Ke9HJA0tTyN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Visualize the Dataset"
      ],
      "metadata": {
        "id": "qs-k0v7BTz8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(X_train[i], cmap='gray')\n",
        "    plt.title(f\"Label: {y_train[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "P_XMKwlnT1pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Build a Feedforward Neural Network"
      ],
      "metadata": {
        "id": "ATQgrXFoT3c4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "jJlAGKYpT44G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Compile and Train"
      ],
      "metadata": {
        "id": "y2v5opQyT6P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "id": "FbKFWKO-T7sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Evaluate the Model"
      ],
      "metadata": {
        "id": "nPSHjszCT9Oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "KlkGyALjT-sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Plot Learning Curves"
      ],
      "metadata": {
        "id": "g1CtuRIUUAJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='train accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LTYqqxwuUBXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Reflection Questions"
      ],
      "metadata": {
        "id": "ZybhRPaH_gwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 6 – Day 3: CNNs for Fashion MNIST\n",
        "\n",
        "Objective\n",
        "\n",
        "Introduce students to convolutional neural networks and show how they improve performance on image classification tasks by leveraging spatial structure.\n",
        "\n",
        "\n",
        "Setup\n",
        "- Platform: Google Colab (TensorFlow pre-installed)\n",
        "- Dataset: Fashion MNIST (same as Day 2, but input needs reshaping for CNN)\n",
        "\n",
        "1. Import Libraries\n"
      ],
      "metadata": {
        "id": "L2gfW52-UDUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "ni5q3NGBUKZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load and Preprocess Data"
      ],
      "metadata": {
        "id": "WWvLWNwFUPVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize and reshape for CNN: (28,28) → (28,28,1)\n",
        "\n",
        "X_train = X_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "X_test = X_test.reshape(-1, 28, 28, 1) / 255.0\n"
      ],
      "metadata": {
        "id": "pKsKKn0XURGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Build a Simple CNN"
      ],
      "metadata": {
        "id": "AVRVaiOUUSt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "])\n"
      ],
      "metadata": {
        "id": "hylgbhynUT_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Compile and Train\n"
      ],
      "metadata": {
        "id": "JylQSfeNUV8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "id": "gBkccDOhUbG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Evaluate and Plot Learning Curve"
      ],
      "metadata": {
        "id": "INcQ87YPUcor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='train accuracy')\n",
        "\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cVWpD2BMUeSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix"
      ],
      "metadata": {
        "id": "oiKc8WdXUgVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_pred = model.predict(X_test).argmax(axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "\n",
        "disp.plot()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RAsuBAdSUiwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 6 – Day 4: Reinforcement Learning – The Vacuum Robot (4×4 Grid)\n",
        "\n",
        "Objective\n",
        "- Introduce students to reinforcement learning by training a vacuum robot using Q-learning in a larger and more complex 4x4 grid world.\n",
        "\n",
        "Scenario\n",
        "- A robot operates in a 4x4 grid (16 locations). Each cell may be dirty or clean.\n",
        "\n",
        "- The agent can move up, down, left, right.\n",
        "\n",
        "- Cleaning a dirty tile gives a reward of +10.\n",
        "\n",
        "- Every move costs -1 (to encourage efficiency)."
      ],
      "metadata": {
        "id": "UvIhUOCjUktN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup: Import Libraries and Initialize Environment\n"
      ],
      "metadata": {
        "id": "098eE_Q8AUth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "PhND95LtAZS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1: Define the Grid World\n",
        "We'll define a 4x4 grid where:\n",
        "\n",
        "Each tile can be clean or dirty.\n",
        "\n",
        "The agent can move up, down, left, right.\n",
        "\n",
        "Cleaning a dirty tile gives a reward of +10.\n",
        "\n",
        "Every move costs -1 (to encourage efficiency)."
      ],
      "metadata": {
        "id": "ar0eCYjTAb5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GRID_SIZE = 4\n",
        "ACTIONS = ['UP', 'DOWN', 'LEFT', 'RIGHT', 'CLEAN']\n",
        "NUM_ACTIONS = len(ACTIONS)\n",
        "\n",
        "def random_dirty_grid():\n",
        "    return np.random.choice([0, 1], size=(GRID_SIZE, GRID_SIZE), p=[0.5, 0.5])\n"
      ],
      "metadata": {
        "id": "YT75Ae0pAeIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2: Define the Environment Dynamics"
      ],
      "metadata": {
        "id": "iixnsK83AgPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VacuumEnv:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.grid = random_dirty_grid()\n",
        "        self.agent_pos = [0, 0]\n",
        "        return self._get_state()\n",
        "\n",
        "    def _get_state(self):\n",
        "        x, y = self.agent_pos\n",
        "        return (x, y, self.grid[x][y])\n",
        "\n",
        "    def step(self, action):\n",
        "        x, y = self.agent_pos\n",
        "        reward = -1  # default move penalty\n",
        "\n",
        "        if action == 'CLEAN':\n",
        "            if self.grid[x][y] == 1:\n",
        "                self.grid[x][y] = 0\n",
        "                reward = 10\n",
        "        else:\n",
        "            if action == 'UP' and x > 0:\n",
        "                x -= 1\n",
        "            elif action == 'DOWN' and x < GRID_SIZE - 1:\n",
        "                x += 1\n",
        "            elif action == 'LEFT' and y > 0:\n",
        "                y -= 1\n",
        "            elif action == 'RIGHT' and y < GRID_SIZE - 1:\n",
        "                y += 1\n",
        "            self.agent_pos = [x, y]\n",
        "\n",
        "        done = np.sum(self.grid) == 0  # all clean\n",
        "        return self._get_state(), reward, done\n"
      ],
      "metadata": {
        "id": "EgpjeiwNAfkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3: Initialize Q-Table"
      ],
      "metadata": {
        "id": "AjUAiuKUAkOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_table = {}\n",
        "\n",
        "def get_q(state):\n",
        "    if state not in q_table:\n",
        "        q_table[state] = np.zeros(NUM_ACTIONS)\n",
        "    return q_table[state]\n"
      ],
      "metadata": {
        "id": "yDP0jK7WAmXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 4: Q-Learning Algorithm"
      ],
      "metadata": {
        "id": "TPUM-8DwAn9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPISODES = 5000\n",
        "LEARNING_RATE = 0.1\n",
        "DISCOUNT = 0.9\n",
        "EPSILON = 0.2\n",
        "\n",
        "for ep in range(EPISODES):\n",
        "    env = VacuumEnv()\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        if random.uniform(0, 1) < EPSILON:\n",
        "            action_idx = random.randint(0, NUM_ACTIONS - 1)\n",
        "        else:\n",
        "            action_idx = np.argmax(get_q(state))\n",
        "\n",
        "        action = ACTIONS[action_idx]\n",
        "        next_state, reward, done = env.step(action)\n",
        "\n",
        "        old_q = get_q(state)[action_idx]\n",
        "        future_q = np.max(get_q(next_state))\n",
        "\n",
        "        new_q = old_q + LEARNING_RATE * (reward + DISCOUNT * future_q - old_q)\n",
        "        get_q(state)[action_idx] = new_q\n",
        "\n",
        "        state = next_state\n"
      ],
      "metadata": {
        "id": "6ZebKiEaAqPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 5: Evaluate the Policy"
      ],
      "metadata": {
        "id": "v3WMG3TEAsQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_episode():\n",
        "    env = VacuumEnv()\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    steps = 0\n",
        "    done = False\n",
        "\n",
        "    while not done and steps < 50:\n",
        "        action_idx = np.argmax(get_q(state))\n",
        "        action = ACTIONS[action_idx]\n",
        "        state, reward, done = env.step(action)\n",
        "        total_reward += reward\n",
        "        steps += 1\n",
        "\n",
        "    return total_reward, steps\n",
        "\n",
        "rewards = [run_episode()[0] for _ in range(100)]\n",
        "print(f\"Average reward over 100 episodes: {np.mean(rewards)}\")\n"
      ],
      "metadata": {
        "id": "F8TxOruHArxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the Learned Policy"
      ],
      "metadata": {
        "id": "f2yIOZzJAxZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy_grid = np.empty((GRID_SIZE, GRID_SIZE), dtype=object)\n",
        "\n",
        "for i in range(GRID_SIZE):\n",
        "    for j in range(GRID_SIZE):\n",
        "        state = (i, j, 1)  # assume dirty tile\n",
        "        best_action = ACTIONS[np.argmax(get_q(state))]\n",
        "        policy_grid[i][j] = best_action\n",
        "\n",
        "print(\"Learned policy (assuming all tiles are dirty):\")\n",
        "print(policy_grid)\n"
      ],
      "metadata": {
        "id": "f2tI98-wAxAy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}